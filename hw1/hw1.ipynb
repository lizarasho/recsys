{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from bisect import bisect_right\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path, names, usecols) -> pd.DataFrame:\n",
    "    return pd.read_csv(file_path, delimiter='::', header=None, names=names, usecols=usecols, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset() -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    ratings_info = read_csv('ml-1m/ratings.dat',\n",
    "                            names=['user_id', 'movie_id', 'rating', 'timestamp'],\n",
    "                            usecols=['user_id', 'movie_id', 'rating'])\n",
    "    movies_info = read_csv('ml-1m/movies.dat',\n",
    "                           names=['movie_id', 'name', 'category'],\n",
    "                           usecols=['movie_id', 'name', 'category'])\n",
    "    return ratings_info, movies_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_by_id(movie_info: pd.DataFrame, size) -> List[str]:\n",
    "    movie_by_id = ['' for _ in range(size)]\n",
    "    for i in range(len(movie_info)):\n",
    "        movie_by_id[movie_info['movie_id'][i] - 1] = movie_info['name'][i]\n",
    "    return movie_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_explicit(ratings_info: pd.DataFrame, movie_info: pd.DataFrame) -> Tuple[sp.csr_matrix, List[str]]:\n",
    "    users = ratings_info['user_id']\n",
    "    movies = ratings_info['movie_id']\n",
    "    user_item = sp.coo_matrix((ratings_info['rating'], (users, movies)))\n",
    "    user_item_csr = user_item.tocsr()[1:, 1:]\n",
    "    return user_item_csr, get_movie_by_id(movie_info, len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_implicit(ratings_info: pd.DataFrame, movie_info: pd.DataFrame) -> Tuple[sp.csr_matrix, List[str]]:\n",
    "    implicit_ratings = ratings_info.loc[(ratings_info['rating'] >= 4)]\n",
    "    users = implicit_ratings['user_id']\n",
    "    movies = implicit_ratings['movie_id']\n",
    "    user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "    user_item_csr = user_item.tocsr()[1:, 1:]\n",
    "    return user_item_csr, get_movie_by_id(movie_info, len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings, movie_info = read_dataset()\n",
    "\n",
    "R_explicit, movie_by_id_explicit = to_explicit(ratings, movie_info)\n",
    "R_implicit, movie_by_id_implicit = to_implicit(ratings, movie_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    return np.linalg.norm(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similars(R: np.ndarray,\n",
    "                 reference_item: np.ndarray,\n",
    "                 item_by_id: List[str],\n",
    "                 similarity_measure, reverse, similars_count=10) -> List[str]:\n",
    "    _, items_count = R.shape\n",
    "\n",
    "    indices = list(range(items_count))\n",
    "    indices.sort(key=lambda index: similarity_measure(reference_item, R[:, index]), reverse=reverse)\n",
    "\n",
    "    return [item_by_id[indices[i]] for i in range(similars_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_X(P: np.ndarray, Q: np.ndarray, biases=None) -> np.ndarray:\n",
    "    X = P @ Q.T\n",
    "\n",
    "    if biases is None:\n",
    "        return X\n",
    "\n",
    "    b_user, b_item, b_common = biases\n",
    "    users_count, items_count = X.shape\n",
    "\n",
    "    for user_index in range(users_count):\n",
    "        for item_index in range(items_count):\n",
    "            X[user_index][item_index] += b_user[user_index] + b_item[item_index] + b_common\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(R, P, Q):\n",
    "    users_count, items_count = R.shape\n",
    "    numerator = 0\n",
    "    denominator = users_count\n",
    "\n",
    "    for user in range(users_count):\n",
    "        _, I_plus = R[user].nonzero()\n",
    "        X_user = [P[user] @ Q[item] for item in range(items_count)]\n",
    "        I_minus = [X_user[item] for item in range(items_count) if item not in I_plus]\n",
    "\n",
    "        if len(I_plus) > 0 and len(I_minus) > 0:\n",
    "            I_minus.sort()\n",
    "            user_numerator = sum([bisect_right(I_minus, X_user[item]) for item in I_plus])\n",
    "            user_denominator = len(I_plus) * len(I_minus)\n",
    "            numerator += user_numerator / user_denominator\n",
    "\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_matrices(users_count, items_count, factors) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    P = np.random.uniform(0, 1 / np.sqrt(factors), size=(users_count, factors))\n",
    "    Q = np.random.uniform(0, 1 / np.sqrt(factors), size=(items_count, factors))\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOY_STORY_ID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACTORS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_RMSE(R, P, Q, biases):\n",
    "    b_user, b_item, b_common = biases\n",
    "    R_users, R_items = R.nonzero()\n",
    "    s = 0\n",
    "    n = 0\n",
    "    for user, item in zip(R_users, R_items):\n",
    "        s += (P[user] @ Q[item] - R[(user, item)] + b_user[user] + b_item[item] + b_common) ** 2\n",
    "        n += 1\n",
    "    return np.sqrt(s / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_bias(R: sp.csr_matrix):\n",
    "    _, cols = R.shape\n",
    "    cols_sums = sp.csr_matrix.sum(R, axis=0)\n",
    "    cols_counts = sp.csr_matrix.sum(R != 0, axis=0)\n",
    "    return np.divide(cols_sums, cols_counts).A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(R: sp.csr_matrix, factors=FACTORS, iterations=5, beta=1e-3, alpha=3e-2):\n",
    "    users_count, items_count = R.shape\n",
    "\n",
    "    P, Q = generate_initial_matrices(users_count, items_count, factors)\n",
    "\n",
    "    b_item = construct_bias(R)\n",
    "    b_user = construct_bias(R.T)\n",
    "    b_common = 0\n",
    "\n",
    "    R_users, R_items = R.nonzero()\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for user, item in zip(R_users, R_items):\n",
    "            eps = P[user] @ Q[item] - R[(user, item)] + b_user[user] + b_item[item] + b_common\n",
    "            P_user = np.copy(P[user])\n",
    "            P[user] -= alpha * (eps * Q[item] + beta * P[user])\n",
    "            Q[item] -= alpha * (eps * P_user + beta * Q[item])\n",
    "            b_user[user] -= alpha * (eps + beta)\n",
    "            b_item[item] -= alpha * (eps + beta)\n",
    "            b_common -= alpha * eps\n",
    "\n",
    "    return P, Q, (b_user, b_item, b_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1(R: sp.csr_matrix, movie_by_id: List[str]):\n",
    "    P, Q, biases = SGD(R)\n",
    "    X = predict_X(P, Q, biases)\n",
    "\n",
    "    similars = get_similars(X, X[:, TOY_STORY_ID], movie_by_id, cosine_distance, True)\n",
    "    rmse_value = SGD_RMSE(R, P, Q, biases)\n",
    "\n",
    "    print('SGD similars: {}'.format(', '.join(similars)))\n",
    "    print('SGD RMSE: {}'.format(rmse_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-3cd001b240d3>:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.divide(cols_sums, cols_counts).A[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD similars: Toy Story (1995), Aladdin (1992), Lion King, The (1994), Little Princess, A (1995), Celluloid Closet, The (1995), Persuasion (1995), Beauty and the Beast (1991), Snow White and the Seven Dwarfs (1937), Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954), Othello (1995)\n",
      "SGD RMSE: 0.6646756099989597\n"
     ]
    }
   ],
   "source": [
    "task1(R_explicit, movie_by_id_explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS_RMSE(R, P, Q, C):\n",
    "    users_count, items_count = R.shape\n",
    "    s = 0\n",
    "    n = 0\n",
    "    for user in range(users_count):\n",
    "        for item in range(items_count):\n",
    "            s += C[user, item] * (P[user] @ Q[item].T - R[user, item]) ** 2\n",
    "            n += 1\n",
    "    return np.sqrt(s / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS_iteration(row, M, MT_M, E, lambda_matrix):\n",
    "    preferences = np.copy(row)\n",
    "    preferences[preferences > 0] = 1\n",
    "\n",
    "    C_minus_E = sp.diags(row, [0])\n",
    "    C = C_minus_E + E\n",
    "\n",
    "    return sp.linalg.spsolve(\n",
    "        MT_M + (M.T @ C_minus_E @ M) + lambda_matrix,\n",
    "        M.T @ C @ preferences.T\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALS(R: sp.csr_matrix, alpha=40, iterations=3, lambda_value=1e-2, factors=64):\n",
    "    users_count, items_count = R.shape\n",
    "\n",
    "    P, Q = generate_initial_matrices(users_count, items_count, factors)\n",
    "    P = sp.csr_matrix(P)\n",
    "    Q = sp.csr_matrix(Q)\n",
    "\n",
    "    C = R * alpha\n",
    "    lambda_matrix = lambda_value * sp.eye(factors)\n",
    "\n",
    "    users_E = sp.eye(users_count)\n",
    "    items_E = sp.eye(items_count)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        QT_Q = Q.T @ Q\n",
    "        PT_P = P.T @ P\n",
    "\n",
    "        for user_index in range(users_count):\n",
    "            P[user_index] = ALS_iteration(\n",
    "                C[user_index, :].toarray(),\n",
    "                Q, QT_Q, items_E, lambda_matrix\n",
    "            )\n",
    "        for item_index in range(items_count):\n",
    "            Q[item_index] = ALS_iteration(\n",
    "                C[:, item_index].T.toarray(),\n",
    "                P, PT_P, users_E, lambda_matrix\n",
    "            )\n",
    "\n",
    "    return P.todense(), Q.todense(), C.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(R: sp.csr_matrix, movie_by_id: List[str]):\n",
    "    P, Q, C = ALS(R)\n",
    "    X = predict_X(P, Q)\n",
    "\n",
    "    similars = get_similars(X, X[:, TOY_STORY_ID], movie_by_id, euclidean_distance, False)\n",
    "    rmse_value = ALS_RMSE(R, P, Q, C)\n",
    "\n",
    "    print('ALS similars: {}'.format(', '.join(similars)))\n",
    "    print('ALS RMSE: {}'.format(rmse_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS similars: Toy Story (1995), Toy Story 2 (1999), Babe (1995), Pleasantville (1998), Lion King, The (1994), There's Something About Mary (1998), Groundhog Day (1993), Clueless (1995), Wayne's World (1992), Aladdin (1992)\n",
      "ALS RMSE: [[0.20536379]]\n"
     ]
    }
   ],
   "source": [
    "task2(R_implicit, movie_by_id_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative(positives, limit):\n",
    "    item = random.randint(0, limit)\n",
    "    while item in positives:\n",
    "        item = random.randint(0, limit)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BPR(R: sp.csr_matrix, factors=FACTORS, alpha=3e-3, beta=2e-2, iterations=1):\n",
    "    users_count, items_count = R.shape\n",
    "\n",
    "    P, Q = generate_initial_matrices(users_count, items_count, factors)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for user in range(users_count):\n",
    "            _, positives = R[user].nonzero()\n",
    "\n",
    "            for pos in positives:\n",
    "                pos_predict = P[user] @ Q[pos]\n",
    "\n",
    "                neg = generate_negative(positives, items_count - 1)\n",
    "                neg_predict = P[user] @ Q[pos]\n",
    "\n",
    "                delta_predict = pos_predict - neg_predict\n",
    "                e = np.exp(-delta_predict)\n",
    "                sigmoid_derivative = e / ((1 + e) ** 2)\n",
    "\n",
    "                P_user = np.copy(P[user])\n",
    "                for f in range(factors):\n",
    "                    P[user][f] += alpha * (sigmoid_derivative * (Q[pos][f] - Q[neg][f]) + beta * P_user[f])\n",
    "                    Q[pos][f] += alpha * (sigmoid_derivative * P_user[f] + beta * Q[pos][f])\n",
    "                    Q[neg][f] += alpha * (-sigmoid_derivative * P_user[f] + beta * Q[neg][f])\n",
    "\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3(R: sp.csr_matrix, movie_by_id: List[str]):\n",
    "    P, Q = BPR(R)\n",
    "    X = predict_X(P, Q)\n",
    "\n",
    "    similars = get_similars(X, X[:, TOY_STORY_ID], movie_by_id, euclidean_distance, False)\n",
    "    auc_value = AUC(R, P, Q)\n",
    "\n",
    "    print('BPR similars: {}'.format(', '.join(similars)))\n",
    "    print('BPR AUC: {}'.format(auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPR similars: Toy Story (1995), Groundhog Day (1993), Alien (1979), Usual Suspects, The (1995), Gladiator (2000), Ghostbusters (1984), Forrest Gump (1994), E.T. the Extra-Terrestrial (1982), Jurassic Park (1993), Men in Black (1997)\n",
      "BPR AUC: 0.8609239129119329\n"
     ]
    }
   ],
   "source": [
    "task3(R_implicit, movie_by_id_implicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WARP(R: sp.csr_matrix, factors=FACTORS, alpha=3e-3, beta=2e-2, iterations=1):\n",
    "    users_count, items_count = R.shape\n",
    "\n",
    "    P, Q = generate_initial_matrices(users_count, items_count, factors)\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for user in range(users_count):\n",
    "            _, positives = R[user].nonzero()\n",
    "            limit = items_count - len(positives)\n",
    "\n",
    "            for pos in positives:\n",
    "                pos_predict = P[user] @ Q[pos]\n",
    "\n",
    "                attempts = 1\n",
    "                neg = generate_negative(positives, items_count - 1)\n",
    "                neg_predict = P[user] @ Q[neg]\n",
    "\n",
    "                while pos_predict >= neg_predict and attempts <= limit:\n",
    "                    attempts += 1\n",
    "                    neg = generate_negative(positives, items_count - 1)\n",
    "                    neg_predict = P[user] @ Q[neg]\n",
    "                if attempts == limit + 1:\n",
    "                    continue\n",
    "\n",
    "                delta_predict = pos_predict - neg_predict\n",
    "                e = np.exp(-delta_predict)\n",
    "                sigmoid_derivative = e / ((1 + e) ** 2)\n",
    "\n",
    "                for f in range(factors):\n",
    "                    P[user][f] += alpha * (sigmoid_derivative * (Q[pos][f] - Q[neg][f]) + beta * P[user][f]) / attempts\n",
    "                    Q[pos][f] += alpha * (sigmoid_derivative * P[user][f] + beta * Q[pos][f]) / attempts\n",
    "                    Q[neg][f] += alpha * (sigmoid_derivative * (-P[user][f]) + beta * Q[neg][f]) / attempts\n",
    "\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task4(R: sp.csr_matrix, movie_by_id: List[str]):\n",
    "    P, Q = WARP(R)\n",
    "    X = predict_X(P, Q)\n",
    "\n",
    "    similars = get_similars(X, X[:, TOY_STORY_ID], movie_by_id, euclidean_distance, False)\n",
    "    auc_value = AUC(R, P, Q)\n",
    "\n",
    "    print('WARP similars: {}'.format(', '.join(similars)))\n",
    "    print('WARP AUC: {}'.format(auc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARP similars: Toy Story (1995), Braveheart (1995), Groundhog Day (1993), Babe (1995), Pulp Fiction (1994), Casablanca (1942), Gladiator (2000), Butch Cassidy and the Sundance Kid (1969), Raiders of the Lost Ark (1981), Indiana Jones and the Last Crusade (1989)\n",
      "WARP AUC: 0.8168461118798038\n"
     ]
    }
   ],
   "source": [
    "task4(R_implicit, movie_by_id_implicit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
